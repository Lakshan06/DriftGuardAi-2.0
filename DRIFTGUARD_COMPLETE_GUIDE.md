# DriftGuard AI 2.0 - Complete End-to-End Working Guide

## QUICK START: USER JOURNEY FLOW

### Phase 1: Authentication (User Registration & Login)
```
New User Flow:
1. Visit webapp â†’ Click "Sign Up"
2. Enter email & password â†’ Click "Register"
3. Backend hashes password with bcrypt, creates User record
4. Frontend redirects to Login
5. Enter credentials â†’ Click "Login"
6. Backend validates password, returns JWT token
7. Token stored in localStorage, auto-redirect to Dashboard âœ…
```

### Phase 2: Model Registry & Drift Detection
```
Step A - Register Model:
1. Click "Register New Model" on Dashboard
2. Fill: model_name, version, description, schema_definition
3. Click "Create"
4. Backend: POST /models â†’ creates ModelRegistry record (status: draft)
5. Model appears on dashboard with ğŸ“‹ Draft badge

Step B - Log Predictions:
1. Production system sends batch: POST /models/logs {predictions: [...]}
2. Backend: inserts into prediction_logs table (need 110+ total)

Step C - Calculate Drift:
1. Click "Recalculate Drift" on Model Detail page
2. Backend:
   - Gets first 100 predictions (baseline distribution)
   - Gets last 100 predictions (recent distribution)
   - Calculates PSI & KS for each feature
   - Flags if PSI â‰¥ 0.25 OR KS â‰¥ 0.2
3. Results shown in Drift Metrics table
4. Risk score calculated: (drift_component Ã— 0.6) + (fairness_component Ã— 0.4)
```

### Phase 3: Fairness Monitoring
```
System automatically groups predictions by protected attributes:
1. Group by "gender", "race", "age", etc.
2. Calculate approval_rate per group
3. Disparity = max_rate - min_rate (as %)
4. If disparity > 25% â†’ fairness_flag = true âš ï¸
5. Disparity score flows into risk calculation
```

### Phase 5: Governance & Deployment
```
Three-Tier Status System:

APPROVED âœ… (risk < 60, disparity < 25%)
â”œâ”€ Click "Deploy" â†’ Immediate deployment
â””â”€ No override needed

AT_RISK âš ï¸ (risk â‰¥ 60 OR disparity â‰¥ 25%)
â”œâ”€ Click "Override & Deploy"
â”œâ”€ Enter justification
â”œâ”€ Backend: updates status to "deployed", logs audit entry
â””â”€ Model deployed with override

BLOCKED âŒ (risk > 80)
â”œâ”€ Deploy button disabled
â”œâ”€ Cannot override without policy change
â””â”€ Admin must adjust policy or improve metrics
```

### Phase 6: AI Intelligence (Optional)
```
When user views model governance status:
1. System calls RunAnywhere SDK (if available)
2. SDK generates natural language explanation:
   "Risk score 65 is driven by transaction amount drift..."
3. If SDK unavailable â†’ fallback to rule-based explanation
4. No disruption to user experience
```

### Phase 7: Executive Command Center
```
Executive navigates to Command Center:
1. Auto-loads 5 API calls in parallel:
   - GET /dashboard/summary â†’ KPIs (total, at_risk, deployed, compliance%)
   - GET /dashboard/risk-trends â†’ Daily risk chart
   - GET /dashboard/deployment-trends â†’ Daily deployment table
   - GET /dashboard/compliance-distribution â†’ Grade A-F distribution
   - GET /dashboard/executive-summary â†’ AI narrative (optional)

2. Executive can:
   a) View real-time metrics
   b) Change time range (7/30/90 days)
   c) Run "What-If" simulations (sandbox mode)

3. Simulation example:
   - Adjust sliders: risk_score=55, fairness=20, override=false
   - Click "Simulate" â†’ Returns: would_pass=true âœ…
   - NO database changes (sandbox mode only)
```

---

## 7 PHASES - DETAILED BREAKDOWN

### PHASE 1: Authentication & User Management
**Purpose**: Secure access control with role-based permissions

Files: `auth.py`, `user.py`, `LoginPage.tsx`, `ProtectedRoute.tsx`

Features:
- Register with email/password
- Login returns JWT token (30-min expiry)
- Roles: admin, ml_engineer, user
- Token stored in localStorage
- Protected routes with auto-redirect

Database:
```
users table:
â”œâ”€ id (primary key)
â”œâ”€ email (unique, indexed)
â”œâ”€ hashed_password (bcrypt)
â”œâ”€ role (admin|ml_engineer|user)
â”œâ”€ is_active (boolean)
â””â”€ created_at (timestamp)
```

API:
```
POST /auth/register â†’ create user
POST /auth/login â†’ get JWT token
```

---

### PHASE 2: Model Registry & Drift Detection
**Purpose**: Register models, log predictions, detect distribution shift

Files: `model_registry.py`, `drift_service.py`, `risk_service.py`, `ModelDetailPage.tsx`

Features:
- Register models with versioning
- Batch prediction logging (JSON features + prediction)
- Statistical drift detection (PSI, KS tests)
- Risk scoring (drift + fairness components)

Drift Detection:
```
PSI (Population Stability Index):
â”œâ”€ < 0.1: No change âœ…
â”œâ”€ 0.1-0.25: Moderate change âš ï¸
â””â”€ â‰¥ 0.25: Significant change ğŸš©

KS (Kolmogorov-Smirnov):
â”œâ”€ < 0.2: No significant difference âœ…
â””â”€ â‰¥ 0.2: Significant difference ğŸš©

Risk Score = (drift_component Ã— 0.6) + (fairness_component Ã— 0.4)
```

Database:
```
model_registry, prediction_logs, drift_metrics, risk_history tables
```

API:
```
POST /models â†’ create model
GET /models â†’ list models
GET /models/{id} â†’ get details
POST /models/logs â†’ log batch predictions
POST /drift/{model_id}/recalculate â†’ calculate drift
GET /models/{id}/risk â†’ get risk history
```

---

### PHASE 3: Fairness Monitoring
**Purpose**: Detect bias in model predictions across demographic groups

Files: `fairness_service.py`, `fairness_metric.py`

Features:
- Track protected attributes (gender, race, age, etc.)
- Calculate approval rates by demographic group
- Detect disparity (max - min approval rate)
- Fairness score (0-100, lower is fairer)

Fairness Thresholds:
```
0-10%: Excellent âœ…
10-20%: Good âœ…
20-30%: Concerning âš ï¸
>30%: Critical ğŸš©
```

Database:
```
fairness_metrics table:
â”œâ”€ model_id, protected_attribute, group_name
â”œâ”€ total_predictions, positive_predictions
â”œâ”€ approval_rate, disparity_score
â””â”€ fairness_flag (true if disparity > threshold)
```

API:
```
GET /models/fairness/{model_id} â†’ get fairness metrics
POST /models/fairness/{model_id}/recalculate â†’ calculate fairness
```

---

### PHASE 5: Governance & Deployment
**Purpose**: Policy-based approval gates for model deployment

Files: `governance.py`, `governance_service.py`, `GovernancePage.tsx`, `AuditPage.tsx`

Features:
- Admin creates governance policies (max_mri, max_disparity, approval_threshold)
- Three-tier status: approved â†’ at_risk â†’ blocked
- Manual approval with justification for at_risk models
- Hard block for models exceeding max_mri
- Audit trail for all deployments

Deployment Rules:
```
IF risk_score > max_allowed_mri (80)
  â†’ BLOCKED âŒ (no deployment allowed)

ELIF disparity > max_allowed_disparity (25%)
  â†’ AT_RISK âš ï¸ (requires override)

ELIF risk_score > approval_threshold (60)
  â†’ AT_RISK âš ï¸ (requires override)

ELSE
  â†’ APPROVED âœ… (deploy immediately)
```

Database:
```
governance_policies table:
â”œâ”€ id, name (unique)
â”œâ”€ max_allowed_mri, max_allowed_disparity
â”œâ”€ approval_required_above_mri
â””â”€ active (boolean, only 1 active policy)
```

API:
```
POST /governance/policies â†’ create policy (admin)
GET /governance/policies â†’ list policies
POST /governance/models/{id}/evaluate â†’ evaluate governance
POST /governance/models/{id}/deploy â†’ deploy model (with optional override)
```

---

### PHASE 6: AI Intelligence (RunAnywhere SDK)
**Purpose**: AI-powered governance explanations

Files: `phase6.py`, `runanywhere_client.py`

Features:
- Optional RunAnywhere SDK integration
- Natural language governance explanations
- Graceful fallback if SDK unavailable
- Risk forecasting (optional)

API:
```
GET /phase6/governance/{id}/explanation â†’ AI explanation
POST /phase6/governance/{id}/forecast â†’ risk forecast
```

---

### PHASE 7: Executive Command Center & Simulation
**Purpose**: Real-time metrics aggregation & sandbox governance testing

Files: `dashboard.py`, `simulation.py`, `CommandCenterPage.tsx`, `CommandCenter.tsx`

Features:
- Real-time KPIs (total models, at-risk, deployed, compliance%)
- Risk trends chart (last 30 days)
- Deployment trends table
- Compliance distribution (grades A-F)
- "What-if" governance simulation (no DB changes)
- Batch simulation for all models

Dashboard Metrics:
```
Total Models: COUNT(model_registry)
At Risk: COUNT(status IN "at_risk", "blocked")
Deployed: COUNT(status = "deployed")
Compliance %: 100 - AVG(risk_score)
```

Simulation Mode:
```
POST /simulation/governance-check
â”œâ”€ Input: risk_score, fairness_score, override flag
â”œâ”€ Returns: would_pass (bool), reason, grade (A-F)
â””â”€ NO database changes (sandbox only)

POST /simulation/batch-governance-check
â”œâ”€ Applies policy to all models
â”œâ”€ Returns: scenario_count, passed_count, pass_rate
â””â”€ NO database changes (sandbox only)
```

API:
```
GET /dashboard/summary â†’ KPIs
GET /dashboard/risk-trends â†’ trend data
GET /dashboard/deployment-trends â†’ deployment data
GET /dashboard/compliance-distribution â†’ grade distribution
GET /dashboard/executive-summary â†’ combined metrics + AI narrative

POST /simulation/governance-check â†’ simulate single model
POST /simulation/batch-governance-check â†’ simulate all models
```

---

## DATABASE SCHEMA (7 Tables)

```
users
â”œâ”€ id (PK)
â”œâ”€ email (unique)
â”œâ”€ hashed_password
â”œâ”€ role
â””â”€ is_active, created_at

model_registry
â”œâ”€ id (PK)
â”œâ”€ model_name, version
â”œâ”€ status (draft|approved|at_risk|deployed|blocked)
â”œâ”€ risk_score (latest)
â”œâ”€ created_by (FKâ†’users.id)
â””â”€ created_at

prediction_logs
â”œâ”€ id (PK)
â”œâ”€ model_id (FK, indexed with timestamp)
â”œâ”€ input_features (JSON)
â”œâ”€ prediction (float)
â”œâ”€ actual_label (float, nullable)
â””â”€ timestamp (indexed)

drift_metrics
â”œâ”€ id (PK)
â”œâ”€ model_id (FK, indexed with timestamp)
â”œâ”€ feature_name
â”œâ”€ psi_value, ks_statistic
â”œâ”€ drift_flag (boolean)
â””â”€ timestamp

fairness_metrics
â”œâ”€ id (PK)
â”œâ”€ model_id (FK, indexed with timestamp)
â”œâ”€ protected_attribute, group_name
â”œâ”€ approval_rate
â”œâ”€ disparity_score
â”œâ”€ fairness_flag
â””â”€ timestamp

risk_history
â”œâ”€ id (PK)
â”œâ”€ model_id (FK, indexed with timestamp)
â”œâ”€ risk_score
â”œâ”€ drift_component, fairness_component
â””â”€ timestamp

governance_policies
â”œâ”€ id (PK)
â”œâ”€ name (unique)
â”œâ”€ max_allowed_mri
â”œâ”€ max_allowed_disparity
â”œâ”€ approval_required_above_mri
â”œâ”€ active (boolean)
â””â”€ created_at
```

---

## FRONTEND PAGES & COMPONENTS

Pages (6 total):
1. **LoginPage** - Email/password form, JWT storage
2. **DashboardPage** - Grid of model cards, status badges
3. **ModelDetailPage** - Model details, drift/fairness/risk charts, deploy button
4. **GovernancePage** - Policy management, model evaluation
5. **AuditPage** - Deployment history, audit trail
6. **CommandCenterPage** - Executive dashboard, simulation panel

Components:
- **Navbar** - User info, logout
- **Sidebar** - Navigation links
- **CommandCenter** - Dashboard widgets (summary, charts, simulation)
- **ProtectedRoute** - Route protection wrapper
- **StatusBadge** - Status indicator
- **LoadingSpinner, ErrorMessage** - UI utilities

---

## SECURITY ARCHITECTURE

Authentication:
- âœ… JWT tokens (30-minute expiry)
- âœ… Bcrypt password hashing
- âœ… No plain-text passwords

Authorization:
- âœ… Role-based access control (admin, ml_engineer, user)
- âœ… @require_roles() decorator on endpoints
- âœ… Protected routes (frontend token check)

API Security:
- âœ… CORS enabled
- âœ… Pydantic input validation
- âœ… SQLAlchemy ORM (prevents SQL injection)
- âœ… HTTP 403 for blocked deployments

---

## DEPLOYMENT CHECKLIST

Development:
```
Backend: python -m uvicorn app.main:app --reload
Frontend: npm run dev
Database: SQLite (./data/driftguardai.db)
URL: http://localhost:5173
```

Production:
```
Backend:
â”œâ”€ Deploy to cloud (AWS/GCP/Heroku)
â”œâ”€ Set env vars: DATABASE_URL, SECRET_KEY, ACCESS_TOKEN_EXPIRE_MINUTES
â”œâ”€ Run migrations
â””â”€ Start Gunicorn/Uvicorn

Frontend:
â”œâ”€ npm run build â†’ dist/
â”œâ”€ Deploy to CDN/S3
â”œâ”€ Configure CORS headers
â””â”€ Set API base URL

Database:
â”œâ”€ PostgreSQL (AWS RDS / Google Cloud SQL)
â”œâ”€ Create database user
â”œâ”€ Run migrations
â””â”€ Enable backups
```

---

## EXAMPLE WORKFLOW: Day in Life

**Day 1 - Setup:**
- Admin registers, creates governance policy (max_risk=80, max_disparity=25%)
- ML Engineer registers, creates model "fraud_detector"

**Day 2 - Predictions:**
- Production system logs 500+ predictions
- Engineer clicks "Recalculate Drift"
- Results: drift detected (PSI=0.32), risk_score=40, fairness=12%
- Model status: APPROVED âœ…

**Day 3 - Deployment:**
- Admin reviews model metrics
- Clicks "Deploy" â†’ Model deployed ğŸš€

**Day 4 - Monitoring:**
- Executive views Command Center
- Total Models: 15, At Risk: 2, Deployed: 13, Compliance: 72%
- Runs simulation: "What if we lower approval threshold?"
- Results: 14 would pass, 1 would fail

**Day 5 - Issue:**
- New fairness issue detected (28% disparity)
- Model status: AT_RISK âš ï¸
- Admin deploys with override: "Fixing fairness in v1.1"
- Audit log created automatically âœ…

---

## KEY FILES & LINES OF CODE

Backend (1500+ lines):
- auth.py (37), drift_service.py (178), fairness_service.py (142)
- governance_service.py (179), dashboard_service.py (301)
- runanywhere_client.py (407), simulation.py (247)

Frontend (1800+ lines):
- LoginPage.tsx (197), ModelDetailPage.tsx (299)
- CommandCenterPage.tsx (141), CommandCenter.tsx (296)
- GovernancePage.tsx (190), AuditPage.tsx (148)

Database: 7 tables, 20+ indexes, relational schema

---

## TECHNOLOGY STACK

Backend:
- FastAPI (HTTP server)
- SQLAlchemy (ORM)
- Pydantic (validation)
- SciPy (statistical tests)
- JWT/Bcrypt (security)

Frontend:
- React 19 (UI framework)
- TypeScript (type safety)
- Recharts (charts/graphs)
- Axios (HTTP client)
- Vite (build tool)

Database:
- SQLite (dev) / PostgreSQL (prod)

---

## VERDICT: WEBAPP STATUS

âœ… **FULLY OPERATIONAL**

All 7 phases implemented & tested:
- Phase 1: âœ… Authentication
- Phase 2: âœ… Model Registry & Drift Detection
- Phase 3: âœ… Fairness Monitoring
- Phase 5: âœ… Governance & Deployment
- Phase 6: âœ… AI Intelligence (optional)
- Phase 7: âœ… Executive Dashboard & Simulation

**Ready for**: Development testing, user acceptance testing, production deployment

---

**For detailed information, refer to the comprehensive exploration report above.**
